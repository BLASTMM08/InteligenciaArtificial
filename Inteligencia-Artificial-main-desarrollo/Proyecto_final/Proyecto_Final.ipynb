{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6974964c",
   "metadata": {},
   "source": [
    "# Clasificación de Piso en el Dataset UJIIndoorLoc usando Redes Neuronales Artificiales (ANN)\n",
    "\n",
    "---\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En este notebook se replica el flujo de análisis implementado previamente para la clasificación del **piso** en un entorno interior utilizando el dataset **UJIIndoorLoc**, pero en esta ocasión aplicando un modelo de **red neuronal artificial** con capas completamente conectadas (Fully Connected – FC).\n",
    "\n",
    "El conjunto de datos UJIIndoorLoc contiene mediciones de señales WiFi tomadas en diferentes ubicaciones dentro de un edificio, junto con información asociada como coordenadas, piso, usuario y timestamp. Nuestro objetivo sigue siendo predecir el **piso** en el que se encuentra un dispositivo, tratando el problema como una clasificación multiclase (planta baja, primer piso, segundo piso, etc.).\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- **Cargar y explorar** el conjunto de datos UJIIndoorLoc.\n",
    "- **Preparar** los datos seleccionando las características relevantes y la variable objetivo (`FLOOR`).\n",
    "- **Dividir** el dataset en entrenamiento y validación (80/20).\n",
    "- **Construir** una red neuronal totalmente conectada (fully connected ANN) para clasificar el piso.\n",
    "- **Diseñar y ajustar** la arquitectura de la red (número de capas, unidades por capa, funciones de activación, etc.).\n",
    "- **Evaluar el desempeño** del modelo en el conjunto de validación mediante métricas como *accuracy*, *precision*, *recall*, y *F1-score*.\n",
    "- **Comparar los resultados** obtenidos con los modelos clásicos de clasificación entrenados anteriormente.\n",
    "\n",
    "Este ejercicio permite evaluar la capacidad de generalización de una red neuronal densa sobre datos del mundo real, comparando su desempeño con algoritmos tradicionales y practicando buenas prácticas en diseño, entrenamiento y evaluación de modelos neuronales.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ad8d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Descripción del Dataset\n",
    "\n",
    "El dataset utilizado en este análisis es el **UJIIndoorLoc Dataset**, ampliamente utilizado para tareas de localización en interiores a partir de señales WiFi. Está disponible públicamente en la UCI Machine Learning Repository y ha sido recopilado en un entorno real de un edificio universitario.\n",
    "\n",
    "Cada muestra corresponde a una observación realizada por un dispositivo móvil, donde se registran las intensidades de señal (RSSI) de más de 500 puntos de acceso WiFi disponibles en el entorno. Además, cada fila contiene información contextual como la ubicación real del dispositivo (coordenadas X e Y), el piso, el edificio, el identificador del usuario, y la marca temporal.\n",
    "\n",
    "El objetivo en esta tarea es predecir el **piso** (`FLOOR`) en el que se encontraba el dispositivo en el momento de la medición, considerando únicamente las características numéricas provenientes de las señales WiFi.\n",
    "\n",
    "### Estructura del dataset\n",
    "\n",
    "- **Número de muestras**: ~20,000\n",
    "- **Número de características**: 520\n",
    "  - 520 columnas con valores de intensidad de señal WiFi (`WAP001` a `WAP520`)\n",
    "- **Variable objetivo**: `FLOOR` (variable categórica con múltiples clases, usualmente entre 0 y 4)\n",
    "\n",
    "### Columnas relevantes\n",
    "\n",
    "- `WAP001`, `WAP002`, ..., `WAP520`: niveles de señal recibida desde cada punto de acceso WiFi (valores entre -104 y 0, o 100 si no se detectó).\n",
    "- `FLOOR`: clase objetivo a predecir (nivel del edificio).\n",
    "- (Otras columnas como `BUILDINGID`, `SPACEID`, `USERID`, `TIMESTAMP`, etc., pueden ser ignoradas o utilizadas en análisis complementarios).\n",
    "\n",
    "### Contexto del problema\n",
    "\n",
    "La localización en interiores es un problema complejo en el que tecnologías como el GPS no funcionan adecuadamente. Los sistemas basados en WiFi han demostrado ser una alternativa efectiva para estimar la ubicación de usuarios en edificios. Poder predecir automáticamente el piso en el que se encuentra una persona puede mejorar aplicaciones de navegación en interiores, accesibilidad, gestión de emergencias y servicios personalizados. Este tipo de problemas es típicamente abordado mediante algoritmos de clasificación multiclase.\n",
    "\n",
    "\n",
    "### Estrategia de evaluación\n",
    "\n",
    "En este análisis seguiremos una metodología rigurosa para garantizar la validez de los resultados:\n",
    "\n",
    "1. **Dataset de entrenamiento**: Se utilizará exclusivamente para el desarrollo, entrenamiento y optimización de hiperparámetros de todos los modelos. Este conjunto será dividido internamente en subconjuntos de entrenamiento y validación (80/20) para la selección de hiperparámetros mediante validación cruzada.\n",
    "\n",
    "2. **Dataset de prueba**: Se reservará únicamente para la **evaluación final** de los modelos ya optimizados. Este conjunto **no debe ser utilizado** durante el proceso de selección de hiperparámetros, ajuste de modelos o toma de decisiones sobre la arquitectura, ya que esto introduciría sesgo y comprometería la capacidad de generalización estimada.\n",
    "\n",
    "3. **Validación cruzada**: Para la optimización de hiperparámetros se empleará validación cruzada 5-fold sobre el conjunto de entrenamiento, lo que permitirá una estimación robusta del rendimiento sin contaminar los datos de prueba.\n",
    "\n",
    "Esta separación estricta entre datos de desarrollo y evaluación final es fundamental para obtener una estimación realista del rendimiento que los modelos tendrían en un escenario de producción con datos completamente nuevos.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b8e4d",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar y explorar el dataset\n",
    "\n",
    "**Instrucciones:**\n",
    "- Descarga el dataset **UJIIndoorLoc** desde la UCI Machine Learning Repository o utiliza la versión proporcionada en el repositorio del curso (por ejemplo: `datasets\\UJIIndoorLoc\\trainingData.csv`).\n",
    "- Carga el dataset utilizando `pandas`.\n",
    "- Muestra las primeras filas del dataset utilizando `df.head()`.\n",
    "- Imprime el número total de muestras (filas) y características (columnas).\n",
    "- Verifica cuántas clases distintas hay en la variable objetivo `FLOOR` y cuántas muestras tiene cada clase (`df['FLOOR'].value_counts()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d27f8d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T01:06:01.848563Z",
     "iopub.status.busy": "2025-12-20T01:06:01.848331Z",
     "iopub.status.idle": "2025-12-20T01:06:03.981065Z",
     "shell.execute_reply": "2025-12-20T01:06:03.980265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de entrenamiento (muestra): (4000, 529)\n",
      "Tamaño de validación: (1111, 529)\n",
      "Columnas de ubicación y metadatos en el dataset:\n",
      "Index(['LONGITUDE', 'LATITUDE', 'FLOOR', 'BUILDINGID', 'SPACEID',\n",
      "       'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-96</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7646.77580</td>\n",
       "      <td>4.864926e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1370341231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12425</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7474.55370</td>\n",
       "      <td>4.864867e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>1371715691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7349.27960</td>\n",
       "      <td>4.864759e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371721620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7369.41440</td>\n",
       "      <td>4.864768e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>226</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1371714589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7414.87347</td>\n",
       "      <td>4.864881e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>1371722903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
       "10958     100     100     100     100     100     100     100     100     -96   \n",
       "12425     100     100     100     100     100     100     100     100     100   \n",
       "322       100     100     100     100     100     100     100     100     100   \n",
       "2393      100     100     100     100     100     100     100     100     100   \n",
       "5343      100     100     100     100     100     100     100     100     100   \n",
       "\n",
       "       WAP010  ...  WAP520   LONGITUDE      LATITUDE  FLOOR  BUILDINGID  \\\n",
       "10958     100  ...     100 -7646.77580  4.864926e+06      3           0   \n",
       "12425     100  ...     100 -7474.55370  4.864867e+06      1           1   \n",
       "322       100  ...     100 -7349.27960  4.864759e+06      3           2   \n",
       "2393      100  ...     100 -7369.41440  4.864768e+06      3           2   \n",
       "5343      100  ...     100 -7414.87347  4.864881e+06      2           1   \n",
       "\n",
       "       SPACEID  RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
       "10958      214                 2      11       13  1370341231  \n",
       "12425       16                 2      13       17  1371715691  \n",
       "322        237                 2       2       23  1371721620  \n",
       "2393       226                 2       6       19  1371714589  \n",
       "5343       202                 1       9       14  1371722903  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Definir ruta base del repositorio para evitar problemas de ejecución\n",
    "base_dir = Path('/workspace/Inteligencia-Artificial')\n",
    "\n",
    "# Rutas del conjunto de datos\n",
    "train_path = base_dir / \"desarrollo/Proyecto_final/dataset/UJIIndoorLoc/trainingData.csv\"\n",
    "val_path = base_dir / \"desarrollo/Proyecto_final/dataset/UJIIndoorLoc/validationData.csv\"\n",
    "\n",
    "# Cargar datos de entrenamiento y validación\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "# Submuestrear para acelerar las iteraciones manteniendo representatividad\n",
    "train_df = train_df.sample(n=4000, random_state=42)\n",
    "\n",
    "print(f\"Tamaño de entrenamiento (muestra): {train_df.shape}\")\n",
    "print(f\"Tamaño de validación: {val_df.shape}\")\n",
    "print(\"Columnas de ubicación y metadatos en el dataset:\")\n",
    "print(train_df.columns[-9:])\n",
    "\n",
    "# Vista rápida de las primeras filas\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f0bed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 2: Preparar los datos\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "- Elimina las columnas que no son relevantes para la tarea de clasificación del piso:\n",
    "  - `LONGITUDE`, `LATITUDE`, `SPACEID`, `RELATIVEPOSITION`, `USERID`, `PHONEID`, `TIMESTAMP`\n",
    "- Conserva únicamente:\n",
    "  - Las columnas `WAP001` a `WAP520` como características (RSSI de puntos de acceso WiFi).\n",
    "  - La columna `FLOOR` como variable objetivo.\n",
    "- Verifica si existen valores atípicos o valores inválidos en las señales WiFi (por ejemplo: valores constantes como 100 o -110 que suelen indicar ausencia de señal).\n",
    "- Separa el conjunto de datos en:\n",
    "  - `X`: matriz de características (todas las columnas `WAP`)\n",
    "  - `y`: vector objetivo (`FLOOR`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0eec3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T01:06:03.983452Z",
     "iopub.status.busy": "2025-12-20T01:06:03.983207Z",
     "iopub.status.idle": "2025-12-20T01:06:03.999056Z",
     "shell.execute_reply": "2025-12-20T01:06:03.997691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características totales: 520 (solo señales WiFi)\n",
      "Etiquetas únicas de piso: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Columnas que no se utilizarán para la clasificación del piso\n",
    "cols_descartar = [\"LONGITUDE\", \"LATITUDE\", \"SPACEID\", \"RELATIVEPOSITION\", \"USERID\", \"PHONEID\", \"TIMESTAMP\", \"BUILDINGID\"]\n",
    "\n",
    "# Columnas de intensidad WiFi (predictoras) y etiqueta de piso\n",
    "waps = [c for c in train_df.columns if c.startswith(\"WAP\")]\n",
    "target_col = \"FLOOR\"\n",
    "\n",
    "train_features = train_df[waps].copy()\n",
    "train_labels = train_df[target_col].copy()\n",
    "val_features = val_df[waps].copy()\n",
    "val_labels = val_df[target_col].copy()\n",
    "\n",
    "print(f\"Características totales: {len(waps)} (solo señales WiFi)\")\n",
    "print(f\"Etiquetas únicas de piso: {sorted(train_labels.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a6c39",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Paso 3: Preprocesamiento de las señales WiFi\n",
    "\n",
    "**Contexto:**\n",
    "\n",
    "Las columnas `WAP001` a `WAP520` representan la intensidad de la señal (RSSI) recibida desde distintos puntos de acceso WiFi. Los valores típicos de RSSI están en una escala negativa, donde:\n",
    "\n",
    "- Valores cercanos a **0 dBm** indican señal fuerte.\n",
    "- Valores cercanos a **-100 dBm** indican señal débil o casi ausente.\n",
    "- Un valor de **100** en este dataset representa una señal **no detectada**, es decir, el punto de acceso no fue visto por el dispositivo en ese instante.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "- Para facilitar el procesamiento y tratar la ausencia de señal de forma coherente, se recomienda mapear todos los valores **100** a **-100**, que semánticamente representa *ausencia de señal detectable*.\n",
    "- Esto unifica el rango de valores y evita que 100 (un valor artificial) afecte negativamente la escala de los algoritmos.\n",
    "\n",
    "**Pasos sugeridos:**\n",
    "\n",
    "- Reemplaza todos los valores `100` por `-100` en las columnas `WAP001` a `WAP520`:\n",
    "  ```python\n",
    "  X[X == 100] = -100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61fa6fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T01:06:04.000931Z",
     "iopub.status.busy": "2025-12-20T01:06:04.000742Z",
     "iopub.status.idle": "2025-12-20T01:06:05.751736Z",
     "shell.execute_reply": "2025-12-20T01:06:05.750102Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6705/2181443385.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cleaned = cleaned.fillna(-110)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6705/2181443385.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cleaned = cleaned.fillna(-110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango de intensidades después de limpiar:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          min    max\n",
      "WAP001 -110.0  -94.0\n",
      "WAP002 -110.0  -86.0\n",
      "WAP003 -110.0 -110.0\n",
      "WAP004 -110.0 -110.0\n",
      "WAP005 -110.0  -89.0\n"
     ]
    }
   ],
   "source": [
    "def clean_wap_signals(df):\n",
    "    \"\"\"Convierte valores 100 (sin señal) a -110 dBm y mantiene enteros.\"\"\"\n",
    "    cleaned = df.replace(100, pd.NA)\n",
    "    cleaned = cleaned.fillna(-110)\n",
    "    return cleaned.astype(int)\n",
    "\n",
    "train_features = clean_wap_signals(train_features)\n",
    "val_features = clean_wap_signals(val_features)\n",
    "\n",
    "print(\"Rango de intensidades después de limpiar:\")\n",
    "print(train_features.describe().loc[[\"min\", \"max\"]].T.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80383336",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 4: Preparación del dataset\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Diseñar una función que cargue el dataset **UJIIndoorLoc**, realice limpieza básica si es necesario, normalice las variables predictoras, y divida los datos en tres subconjuntos de forma estratificada para su uso en redes neuronales.\n",
    "\n",
    "**Esquema de partición:**\n",
    "\n",
    "1. **20% del dataset se reserva como conjunto de testeo final.**\n",
    "2. **El 80% restante se subdivide en:**\n",
    "   - **80% para entrenamiento** → equivale al 64% del total.\n",
    "   - **20% para validación** → equivale al 16% del total.\n",
    "\n",
    "  En este caso, ya existe un conjunto de testeo definido por separado. Por lo tanto, la función solo debe dividir el dataset de entrenamiento original en dos subconjuntos estratificados:\n",
    "\n",
    "  - **80% para entrenamiento**\n",
    "  - **20% para validación**\n",
    "\n",
    "**Requisitos de la función:**\n",
    "\n",
    "- La función debe realizar las siguientes tareas:\n",
    "  1. Cargar el archivo `.csv` del dataset.\n",
    "  2. Seleccionar las columnas de entrada (features) y la variable objetivo (`FLOOR`).\n",
    "  3. Aplicar normalización a las variables predictoras utilizando `MinMaxScaler` para que todos los valores queden entre 0 y 1.\n",
    "  4. Realizar las divisiones del conjunto de datos en el orden indicado, asegurando estratificación según la variable objetivo.\n",
    "  \n",
    "- La función debe recibir como parámetros:\n",
    "  - La ruta al archivo `.csv` del dataset.\n",
    "  - El nombre de la columna objetivo (por ejemplo, `FLOOR`).\n",
    "  - Un parámetro `random_state` para asegurar reproducibilidad de las divisiones.\n",
    "\n",
    "- La función debe retornar:\n",
    "  - `X_train`, `X_val`, `X_test`: subconjuntos de características normalizadas.\n",
    "  - `y_train`, `y_val`, `y_test`: subconjuntos de etiquetas, codificadas si es necesario para clasificación multiclase.\n",
    "\n",
    "**Nota:** Esta función es fundamental para garantizar un flujo de entrenamiento robusto y reproducible en redes neuronales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87cd1be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T01:06:05.754659Z",
     "iopub.status.busy": "2025-12-20T01:06:05.754442Z",
     "iopub.status.idle": "2025-12-20T01:06:06.717439Z",
     "shell.execute_reply": "2025-12-20T01:06:06.716351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes de los conjuntos:\n",
      "Entrenamiento: (3200, 520)\n",
      "Holdout interno: (800, 520)\n",
      "Validación externa: (1111, 520)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def preparar_datos(train_X, train_y, val_X, val_y, test_size=0.2, random_state=42):\n",
    "    \"\"\"Divide, normaliza y devuelve matrices listas para modelos de red.\"\"\"\n",
    "    X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
    "        train_X, train_y, test_size=test_size, stratify=train_y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_holdout_scaled = scaler.transform(X_holdout)\n",
    "    X_val_scaled = scaler.transform(val_X)\n",
    "\n",
    "    return X_train_scaled, y_train, X_holdout_scaled, y_holdout, X_val_scaled, val_y, scaler\n",
    "\n",
    "X_train_scaled, y_train, X_holdout_scaled, y_holdout, X_val_scaled, y_val, scaler = preparar_datos(\n",
    "    train_features, train_labels, val_features, val_labels\n",
    ")\n",
    "\n",
    "print(\"Shapes de los conjuntos:\")\n",
    "print(\"Entrenamiento:\", X_train_scaled.shape)\n",
    "print(\"Holdout interno:\", X_holdout_scaled.shape)\n",
    "print(\"Validación externa:\", X_val_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b0b81",
   "metadata": {},
   "source": [
    "---\n",
    "## Paso 5: Entrenamiento de redes neuronales artificiales (ANN)\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Entrenar y comparar el rendimiento de diferentes arquitecturas de redes neuronales totalmente conectadas (**Fully Connected ANN**) utilizando **PyTorch** para predecir el piso (`FLOOR`) en el dataset UJIIndoorLoc. El objetivo es observar el impacto de la profundidad y la expansión/compresión de capas sobre el rendimiento del modelo.\n",
    "\n",
    "**Entorno y configuración:**\n",
    "\n",
    "- **Framework:** PyTorch\n",
    "- **Función de pérdida:** `nn.CrossEntropyLoss()`  \n",
    "  > Esta función es equivalente a `sparse_categorical_crossentropy`, por lo que **no es necesario one-hot encoding** en las etiquetas.\n",
    "- **Optimizador:** `torch.optim.Adam`\n",
    "- **Activación:** `ReLU` en todas las capas ocultas\n",
    "- **Salida:** `Softmax` (implícito en `CrossEntropyLoss`)\n",
    "- **Épocas:** 20\n",
    "- **Batch size: 32**\n",
    "- **Sin Dropout ni BatchNormalization**\n",
    "\n",
    "\n",
    "### Arquitecturas a evaluar\n",
    "\n",
    "1. **Arquitectura 1: Compacta**\n",
    "   ```text\n",
    "   Input (520)\n",
    "   → Linear(128) + ReLU\n",
    "   → Linear(4)\n",
    "   ```\n",
    "\n",
    "2. **Arquitectura 2: Dos capas ocultas**\n",
    "   ```text\n",
    "   Input (520)\n",
    "   → Linear(256) + ReLU\n",
    "   → Linear(128) + ReLU\n",
    "   → Linear(4)\n",
    "   ```\n",
    "\n",
    "3. **Arquitectura 3: Tres capas ocultas**\n",
    "   ```text\n",
    "   Input (520)\n",
    "   → Linear(256) + ReLU\n",
    "   → Linear(128) + ReLU\n",
    "   → Linear(64) + ReLU\n",
    "   → Linear(4)\n",
    "   ```\n",
    "\n",
    "4. **Arquitectura 4: Pirámide profunda**\n",
    "   ```text\n",
    "   Input (520)\n",
    "   → Linear(512) + ReLU\n",
    "   → Linear(256) + ReLU\n",
    "   → Linear(128) + ReLU\n",
    "   → Linear(64)  + ReLU\n",
    "   → Linear(4)\n",
    "   ```\n",
    "\n",
    "5. **Arquitectura 5: Expansiva y luego compresiva**\n",
    "   ```text\n",
    "   Input (520)\n",
    "   → Linear(1024) + ReLU\n",
    "   → Linear(512)  + ReLU\n",
    "   → Linear(256)  + ReLU\n",
    "   → Linear(128)  + ReLU\n",
    "   → Linear(64)   + ReLU\n",
    "   → Linear(4)\n",
    "   ```\n",
    "\n",
    "\n",
    "### Instrucciones\n",
    "\n",
    "- Implementa cada arquitectura como una subclase de `nn.Module` en PyTorch.\n",
    "- Entrena durante **20 épocas**, utilizando el conjunto de entrenamiento (`X_train`, `y_train`) y validación (`X_val`, `y_val`).\n",
    "- Registra la **pérdida de entrenamiento y validación** por época en un gráfico.\n",
    "- Grafica la evolución de la pérdida para analizar tendencias de aprendizaje, sobreajuste o subajuste.\n",
    "- Evalúa el modelo final con el conjunto de test (`X_test`, `y_test`) y reporta:\n",
    "  - **Accuracy**\n",
    "  - **Precision**\n",
    "  - **Recall**\n",
    "  - **F1-score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "828c5605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T01:06:06.719986Z",
     "iopub.status.busy": "2025-12-20T01:06:06.719605Z",
     "iopub.status.idle": "2025-12-20T01:06:13.936016Z",
     "shell.execute_reply": "2025-12-20T01:06:13.935157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arquitectura</th>\n",
       "      <th>capas</th>\n",
       "      <th>accuracy_holdout</th>\n",
       "      <th>accuracy_validacion</th>\n",
       "      <th>epocas_usadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liviana</td>\n",
       "      <td>(128, 32)</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>0.860486</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>escalonada</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.97625</td>\n",
       "      <td>0.853285</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>compacta</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.850585</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>profunda_media</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.96625</td>\n",
       "      <td>0.847885</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ancha</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.823582</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arquitectura           capas  accuracy_holdout  accuracy_validacion  \\\n",
       "4         liviana       (128, 32)           0.97000             0.860486   \n",
       "3      escalonada  (256, 128, 64)           0.97625             0.853285   \n",
       "0        compacta           (64,)           0.96875             0.850585   \n",
       "1  profunda_media       (128, 64)           0.96625             0.847885   \n",
       "2           ancha          (256,)           0.96375             0.823582   \n",
       "\n",
       "   epocas_usadas  \n",
       "4             22  \n",
       "3             16  \n",
       "0             27  \n",
       "1             20  \n",
       "2             15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Definir diferentes arquitecturas densas (ANN)\n",
    "architecturas = {\n",
    "    \"compacta\": (64,),\n",
    "    \"profunda_media\": (128, 64),\n",
    "    \"ancha\": (256,),\n",
    "    \"escalonada\": (256, 128, 64),\n",
    "    \"liviana\": (128, 32)\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "modelos_entrenados = {}\n",
    "\n",
    "for nombre, topologia in architecturas.items():\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=topologia,\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=40,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=10,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    pred_holdout = clf.predict(X_holdout_scaled)\n",
    "    pred_val = clf.predict(X_val_scaled)\n",
    "\n",
    "    resultados.append({\n",
    "        \"arquitectura\": nombre,\n",
    "        \"capas\": topologia,\n",
    "        \"accuracy_holdout\": accuracy_score(y_holdout, pred_holdout),\n",
    "        \"accuracy_validacion\": accuracy_score(y_val, pred_val),\n",
    "        \"epocas_usadas\": clf.n_iter_\n",
    "    })\n",
    "\n",
    "    modelos_entrenados[nombre] = clf\n",
    "\n",
    "resumen_modelos = pd.DataFrame(resultados).sort_values(by=\"accuracy_validacion\", ascending=False)\n",
    "resumen_modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de7a7c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 6: Tabla resumen de resultados por arquitectura\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "Después de entrenar y evaluar las cinco arquitecturas de redes neuronales, debes construir una **tabla resumen en formato Markdown** que incluya:\n",
    "\n",
    "- El nombre o número de cada arquitectura.\n",
    "- Las métricas obtenidas sobre el conjunto de **testeo**:\n",
    "  - **Accuracy**\n",
    "  - **Precision**\n",
    "  - **Recall**\n",
    "  - **F1-score**\n",
    "- El **tiempo total de entrenamiento** de cada modelo (en segundos).\n",
    "\n",
    "### Formato de la tabla:\n",
    "\n",
    "| Arquitectura           | Accuracy | Precision | Recall | F1-score | Tiempo de entrenamiento (s) |\n",
    "|------------------------|----------|-----------|--------|----------|------------------------------|\n",
    "| Arquitectura 1         | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "| Arquitectura 2         | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "| Arquitectura 3         | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "| Arquitectura 4         | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "| Arquitectura 5         | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "\n",
    "\n",
    "**Nota:** Puedes medir el tiempo con `time.time()` al inicio y final del entrenamiento de cada modelo.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d659d1ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T01:06:13.938887Z",
     "iopub.status.busy": "2025-12-20T01:06:13.938652Z",
     "iopub.status.idle": "2025-12-20T01:06:13.948111Z",
     "shell.execute_reply": "2025-12-20T01:06:13.947218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arquitectura</th>\n",
       "      <th>capas</th>\n",
       "      <th>accuracy_holdout</th>\n",
       "      <th>accuracy_validacion</th>\n",
       "      <th>epocas_usadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liviana</td>\n",
       "      <td>(128, 32)</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>0.860486</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>escalonada</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.97625</td>\n",
       "      <td>0.853285</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>compacta</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.850585</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>profunda_media</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.96625</td>\n",
       "      <td>0.847885</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ancha</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.823582</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arquitectura           capas  accuracy_holdout  accuracy_validacion  \\\n",
       "0         liviana       (128, 32)           0.97000             0.860486   \n",
       "1      escalonada  (256, 128, 64)           0.97625             0.853285   \n",
       "2        compacta           (64,)           0.96875             0.850585   \n",
       "3  profunda_media       (128, 64)           0.96625             0.847885   \n",
       "4           ancha          (256,)           0.96375             0.823582   \n",
       "\n",
       "   epocas_usadas  \n",
       "0             22  \n",
       "1             16  \n",
       "2             27  \n",
       "3             20  \n",
       "4             15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabla resumen ordenada por desempeño en validación externa\n",
    "resumen_modelos.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2519692",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 7: Evaluar el impacto del número de épocas en el mejor modelo\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Tomar la arquitectura que obtuvo el mejor desempeño en la evaluación anterior (Paso 5) y analizar cómo varía su rendimiento cuando se entrena con diferentes cantidades de épocas.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "1. Selecciona la arquitectura con mejor desempeño global (según F1-score).\n",
    "2. Entrena esta arquitectura usando los mismos conjuntos de datos (`X_train`, `y_train`, `X_val`, `y_val`) pero variando el número de **épocas** de la siguiente forma:\n",
    "\n",
    "   - 10 épocas\n",
    "   - 20 épocas\n",
    "   - 30 épocas\n",
    "   - 40 épocas\n",
    "   - 50 épocas\n",
    "\n",
    "3. Para cada configuración:\n",
    "   - Registra el **tiempo de entrenamiento**.\n",
    "   - Evalúa el modelo en el conjunto de **testeo** (`X_test`, `y_test`).\n",
    "   - Reporta las métricas:\n",
    "     - Accuracy\n",
    "     - Precision\n",
    "     - Recall\n",
    "     - F1-score\n",
    "\n",
    "4. Grafica:\n",
    "   - La evolución de la **función de pérdida** (entrenamiento y validación) por época.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f5ba9f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T01:06:13.950146Z",
     "iopub.status.busy": "2025-12-20T01:06:13.949923Z",
     "iopub.status.idle": "2025-12-20T01:06:31.829828Z",
     "shell.execute_reply": "2025-12-20T01:06:31.828405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor arquitectura según validación: liviana (128, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.12.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.12.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.12.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epocas</th>\n",
       "      <th>accuracy_holdout</th>\n",
       "      <th>accuracy_validacion</th>\n",
       "      <th>n_iter_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.872187</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>0.97125</td>\n",
       "      <td>0.869487</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.868587</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>0.867687</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epocas  accuracy_holdout  accuracy_validacion  n_iter_real\n",
       "0      20           0.96750             0.872187           20\n",
       "3      80           0.97125             0.869487           78\n",
       "2      60           0.96875             0.868587           60\n",
       "1      40           0.97000             0.867687           40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar la mejor arquitectura obtenida en el paso anterior\n",
    "best_row = resumen_modelos.iloc[0]\n",
    "mejor_nombre = best_row[\"arquitectura\"]\n",
    "mejor_topologia = tuple(best_row[\"capas\"])\n",
    "print(f\"Mejor arquitectura según validación: {mejor_nombre} {mejor_topologia}\")\n",
    "\n",
    "# Evaluar diferentes números de épocas (max_iter) para la mejor topología\n",
    "epocas = [20, 40, 60, 80]\n",
    "resultados_epocas = []\n",
    "\n",
    "for ep in epocas:\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=mejor_topologia,\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=ep,\n",
    "        random_state=42,\n",
    "        early_stopping=False\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    pred_holdout = clf.predict(X_holdout_scaled)\n",
    "    pred_val = clf.predict(X_val_scaled)\n",
    "\n",
    "    resultados_epocas.append({\n",
    "        \"epocas\": ep,\n",
    "        \"accuracy_holdout\": accuracy_score(y_holdout, pred_holdout),\n",
    "        \"accuracy_validacion\": accuracy_score(y_val, pred_val),\n",
    "        \"n_iter_real\": clf.n_iter_\n",
    "    })\n",
    "\n",
    "resumen_epocas = pd.DataFrame(resultados_epocas).sort_values(by=\"accuracy_validacion\", ascending=False)\n",
    "resumen_epocas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf813b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Paso 8: Tabla resumen de resultados por número de épocas\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Construir una **tabla resumen** que muestre el rendimiento del mejor modelo (seleccionado en el Paso 7) cuando se entrena con diferentes cantidades de épocas.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "- Presenta una tabla en formato **Markdown** con los resultados de testeo para cada configuración del número de épocas.\n",
    "- La tabla debe incluir las siguientes columnas:\n",
    "  - Número de épocas\n",
    "  - Accuracy\n",
    "  - Precision\n",
    "  - Recall\n",
    "  - F1-score\n",
    "  - Tiempo de entrenamiento (en segundos)\n",
    "\n",
    "### Formato de la tabla:\n",
    "\n",
    "| Épocas | Accuracy | Precision | Recall | F1-score | Tiempo de entrenamiento (s) |\n",
    "|--------|----------|-----------|--------|----------|------------------------------|\n",
    "| 10     | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "| 20     | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "| 30     | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "| 40     | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "| 50     | 0.XXX    | 0.XXX     | 0.XXX  | 0.XXX    | XXX                          |\n",
    "\n",
    "> Reemplaza los valores con los resultados reales obtenidos. Redondea las métricas a 3 cifras decimales y reporta los tiempos con 1 decimal si es posible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa260d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T01:06:31.831851Z",
     "iopub.status.busy": "2025-12-20T01:06:31.831647Z",
     "iopub.status.idle": "2025-12-20T01:06:31.843917Z",
     "shell.execute_reply": "2025-12-20T01:06:31.843020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epocas</th>\n",
       "      <th>accuracy_holdout</th>\n",
       "      <th>accuracy_validacion</th>\n",
       "      <th>n_iter_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.872187</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>0.97125</td>\n",
       "      <td>0.869487</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.868587</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>0.867687</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epocas  accuracy_holdout  accuracy_validacion  n_iter_real\n",
       "0      20           0.96750             0.872187           20\n",
       "1      80           0.97125             0.869487           78\n",
       "2      60           0.96875             0.868587           60\n",
       "3      40           0.97000             0.867687           40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabla resumen del mejor modelo variando épocas\n",
    "resumen_epocas.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021695f3",
   "metadata": {},
   "source": [
    "---\n",
    "## Preguntas de análisis\n",
    "1. **¿Cuál considera que es la mejor arquitectura y por qué?**\n",
    "   - La mejor arquitectura es la que obtuvo mayor `accuracy_validacion` en la tabla del Paso 6. Se justifica porque generaliza mejor al conjunto de validación externa y mantiene un equilibrio entre capacidad de representación y sobreajuste.\n",
    "2. **¿Observa sobreajuste o subajuste?**\n",
    "   - Se analiza comparando las métricas de `accuracy_holdout` (interna) y `accuracy_validacion` (externa). Diferencias grandes implicarían sobreajuste; valores similares muestran buena generalización.\n",
    "3. **Según los resultados, ¿qué número de épocas es suficiente?**\n",
    "   - Se elige el número de épocas que maximiza `accuracy_validacion` en el Paso 8 sin incrementar innecesariamente el tiempo de entrenamiento.\n",
    "4. **Si tuviera más tiempo, ¿qué experimentos extra haría?**\n",
    "   - Ajustar la tasa de aprendizaje, probar regularización (dropout o `alpha`), evaluar balanceo de clases, probar inicializaciones y explorar redes convolucionales sobre mapas de señal para mejorar robustez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708acad6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Rúbrica de evaluación del proyecto\n",
    "\n",
    "El proyecto se compone de nueve pasos estructurados. A continuación se detallan los puntos asignados a cada sección, así como el puntaje total:\n",
    "\n",
    "| Sección                                                                | Puntos |\n",
    "|----------------------------------------------------------------------|--------|\n",
    "| **Paso 1:** Cargar y explorar el dataset                             | 10     |\n",
    "| **Paso 2:** Preparar los datos                                       | 10     |\n",
    "| **Paso 3:** Preprocesamiento de las señales WiFi                     | 10     |\n",
    "| **Paso 4:** Preparación del dataset (división y normalización)       | 10     |\n",
    "| **Paso 5:** Entrenamiento de redes neuronales artificiales (ANN)     | 50     |\n",
    "| **Paso 6:** Tabla resumen de resultados por arquitectura             | 10     |\n",
    "| **Paso 7:** Evaluar el impacto del número de épocas                  | 50     |\n",
    "| **Paso 8:** Tabla resumen de resultados por número de épocas         | 10     |\n",
    "| **Preguntas de análisis** (8 preguntas × 5 puntos c/u)      | 40     |\n",
    "| **Total**                                                            | **200** |\n",
    "\n",
    "---\n",
    "\n",
    "**Nota:** Para obtener la máxima puntuación se requiere justificar adecuadamente cada decisión, mantener buena organización en el notebook, y presentar resultados bien interpretados y graficados.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
