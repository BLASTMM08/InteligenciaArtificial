{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c774c713",
   "metadata": {},
   "source": [
    "## Descripción del dataset: Pima Indians Diabetes\n",
    "\n",
    "El **Pima Indians Diabetes Dataset** es un conjunto de datos clásico en Machine Learning y bioestadística, recopilado por el *National Institute of Diabetes and Digestive and Kidney Diseases*.  \n",
    "Su propósito es **predecir la aparición de diabetes tipo 2** en mujeres de origen **pima** (una población indígena del sur de Arizona, EE.UU.), a partir de diversas variables clínicas y demográficas.\n",
    "\n",
    "### Características principales:\n",
    "- **Número de registros:** 392 (en esta versión limpia, el original tenía 768).  \n",
    "- **Número de atributos (features):** 8 variables predictoras + 1 variable objetivo.  \n",
    "- **Población:** Mujeres de al menos 21 años de edad de la etnia Pima.  \n",
    "- **Tarea principal:** Clasificación binaria → determinar si una paciente tiene diabetes (`Outcome = 1`) o no (`Outcome = 0`).\n",
    "\n",
    "### Variables:\n",
    "1. **Pregnancies** → Número de embarazos.  \n",
    "2. **Glucose** → Concentración de glucosa en plasma después de 2 horas en una prueba de tolerancia a la glucosa.  \n",
    "3. **BloodPressure** → Presión arterial diastólica (mm Hg).  \n",
    "4. **SkinThickness** → Espesor del pliegue cutáneo del tríceps (mm).  \n",
    "5. **Insulin** → Nivel sérico de insulina (mu U/ml).  \n",
    "6. **BMI** → Índice de masa corporal (peso en kg / altura² en m²).  \n",
    "7. **DiabetesPedigreeFunction** → Probabilidad de diabetes basada en antecedentes familiares.  \n",
    "8. **Age** → Edad en años.  \n",
    "9. **Outcome** → Variable objetivo:  \n",
    "   - `0` = No tiene diabetes  \n",
    "   - `1` = Tiene diabetes  \n",
    "\n",
    "### Relevancia:\n",
    "Este dataset es ampliamente utilizado en cursos de **Inteligencia Artificial y Machine Learning** para enseñar:\n",
    "- Procesamiento y limpieza de datos biomédicos.  \n",
    "- Métodos de clasificación supervisada (KNN, regresión logística, Random Forest, SVM, redes neuronales, etc.).  \n",
    "- Importancia de la normalización y estandarización en algoritmos basados en distancias.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89ef96",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar la base de datos  \n",
    "Cargamos el CSV en un `DataFrame` de `pandas`. Si tu archivo no se llama exactamente `cleaned_dataset.csv`, ajusta la ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17934010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Cargar el dataset limpio\n",
    "DATA_PATH = Path('dataset') / 'cleaned_dataset.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Filas y columnas: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b7ef2",
   "metadata": {},
   "source": [
    "## Paso 2: Crear subconjuntos con 20 datos de **entrenamiento** y 20 de **testeo**\n",
    "Seleccionaremos 40 muestras: 20 para entrenar y 20 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seleccionamos 40 muestras al azar para trabajar el ejemplo manual\n",
    "subset = df.sample(n=40, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_subset = subset.drop(columns=['Outcome'])\n",
    "y_subset = subset['Outcome']\n",
    "\n",
    "# 20 para entrenamiento, 20 para prueba\n",
    "testable = 20\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "    X_subset, y_subset, test_size=testable, random_state=42, stratify=y_subset\n",
    ")\n",
    "\n",
    "print(f\"Entrenamiento: {X_train_small.shape}, Prueba: {X_test_small.shape}\")\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1e8d1",
   "metadata": {},
   "source": [
    "## Paso 3: Implementar la función de distancia euclidiana\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función en Python que reciba dos vectores y calcule la distancia euclidiana entre ellos.\n",
    "- Utiliza la siguiente fórmula matemática para la distancia euclidiana entre dos vectores $x$ y $y$ de $n$ dimensiones:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "- Prueba tu función con los siguientes dos ejemplos (cada vector corresponde a una fila del dataset):\n",
    "\n",
    "| Embarazos | Glucosa | Presión Arterial | Grosor Piel | Insulina | IMC  | Función Hereditaria | Edad | Resultado |\n",
    "|-----------|---------|------------------|-------------|----------|------|---------------------|------|-----------|\n",
    "|     1     |   106   |        70        |      28     |   135    | 34.2 |        0.142        |  22  |     0     |\n",
    "|     2     |   102   |        86        |      36     |   120    | 45.5 |        0.127        |  23  |     1     |\n",
    "\n",
    "- Calcula la distancia euclidiana a mano y luego verifica que el resultado de tu función sea el mismo.\n",
    "- La función debe imprimir el resultado del cálculo de la distancia euclidiana con los datos presentados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa56bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    x = np.array(x, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Prueba con los dos vectores indicados\n",
    "vector_a = [1, 106, 70, 28, 135, 34.2, 0.142, 22, 0]\n",
    "vector_b = [2, 102, 86, 36, 120, 45.5, 0.127, 23, 1]\n",
    "\n",
    "distancia_demo = euclidean_distance(vector_a[:-1], vector_b[:-1])\n",
    "print(f\"Distancia euclidiana de ejemplo: {distancia_demo:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73bbcc",
   "metadata": {},
   "source": [
    "## Paso 4: Implementar un clasificador KNN básico\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función que, dado un punto de prueba, calcule la distancia a todos los puntos de entrenamiento utilizando tu función de distancia euclidiana.\n",
    "- Selecciona los **k = 3** vecinos más cercanos y predice la clase mayoritaria entre ellos.\n",
    "- Aplica tu función a las 10 muestras de prueba obtenidas previamente, utilizando las 10 muestras de entrenamiento como referencia.\n",
    "- El script debe imprimir una tabla comparando el valor real de `Resultado` de cada muestra de prueba con el valor predicho por tu algoritmo.\n",
    "- Considere que las tablas se pueden codificar con un formato similar al que se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d1223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def knn_predict(point, X_train, y_train, k=3):\n",
    "    distancias = []\n",
    "    for idx, fila in enumerate(X_train.values):\n",
    "        dist = euclidean_distance(point, fila)\n",
    "        distancias.append((dist, y_train.iloc[idx]))\n",
    "    distancias.sort(key=lambda x: x[0])\n",
    "    vecinos = [label for _, label in distancias[:k]]\n",
    "    conteo = Counter(vecinos)\n",
    "    # En caso de empate, se devuelve la clase con mayor frecuencia y menor etiqueta\n",
    "    return max(conteo.items(), key=lambda x: (x[1], -x[0]))[0]\n",
    "\n",
    "\n",
    "# Aplicamos el KNN manual a las 20 muestras de prueba\n",
    "predicciones = [\n",
    "    knn_predict(row, X_train_small, y_train_small, k=3)\n",
    "    for row in X_test_small.values\n",
    "]\n",
    "\n",
    "resultados_manual = pd.DataFrame(\n",
    "    {\n",
    "        'Real': y_test_small.values,\n",
    "        'Predicho': predicciones,\n",
    "    }\n",
    ")\n",
    "\n",
    "accuracy_manual = (resultados_manual['Real'] == resultados_manual['Predicho']).mean()\n",
    "print(\"Tabla de comparación (subset 20/20):\")\n",
    "print(resultados_manual.head(10))\n",
    "print(f\"Accuracy manual (subset): {accuracy_manual:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f7f05",
   "metadata": {},
   "source": [
    "## Paso 5: Usar toda la data con separación 80% entrenamiento / 20% testeo  \n",
    "\n",
    "### Pasos:\n",
    "1. Cargar todo el dataset.  \n",
    "2. Separar variables (X) y etiquetas (y).  \n",
    "3. Aplicar `train_test_split` con 80% para entrenamiento y 20% para testeo.  \n",
    "4. Mantener la proporción de clases usando estratificación.  \n",
    "5. Guardar los conjuntos de datos para usarlos en KNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb071d8",
   "metadata": {},
   "source": [
    "## Paso 6: Entrenar un KNN con los datos sin escalar (crudos) y calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Definir el valor de **k = 3** y el metodo **Euclidiano**.  \n",
    "2. Entrenar el modelo KNN con los datos crudos (sin normalizar/estandarizar).  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** comparando predicciones con etiquetas reales.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_raw = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_raw.fit(X_train, y_train)\n",
    "\n",
    "y_pred_raw = knn_raw.predict(X_test)\n",
    "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
    "\n",
    "print(f\"Accuracy datos crudos: {accuracy_raw:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82664821",
   "metadata": {},
   "source": [
    "## Paso 7: Normalizar (Min-Max scaling) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **normalización Min-Max** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos normalizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32694423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_train_norm = minmax_scaler.fit_transform(X_train)\n",
    "X_test_norm = minmax_scaler.transform(X_test)\n",
    "\n",
    "knn_norm = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_norm.fit(X_train_norm, y_train)\n",
    "\n",
    "y_pred_norm = knn_norm.predict(X_test_norm)\n",
    "accuracy_norm = accuracy_score(y_test, y_pred_norm)\n",
    "\n",
    "print(f\"Accuracy datos normalizados (Min-Max): {accuracy_norm:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6519b",
   "metadata": {},
   "source": [
    "## Paso 9: Estandarizar (Z-score) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **estandarización Z-score** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos estandarizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "X_train_std = std_scaler.fit_transform(X_train)\n",
    "X_test_std = std_scaler.transform(X_test)\n",
    "\n",
    "knn_std = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_std.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred_std = knn_std.predict(X_test_std)\n",
    "accuracy_std = accuracy_score(y_test, y_pred_std)\n",
    "\n",
    "print(f\"Accuracy datos estandarizados (Z-score): {accuracy_std:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58946086",
   "metadata": {},
   "source": [
    "## Paso 10/11: Tabla comparativa de accuracies  \n",
    "\n",
    "### Pasos:\n",
    "1. Reunir los resultados de accuracy de cada experimento:  \n",
    "   - KNN sin escalar (80/20).  \n",
    "   - KNN normalizado (80/20).  \n",
    "   - KNN estandarizado (80/20).  \n",
    "2. Crear una tabla con los resultados.  \n",
    "3. Comparar el desempeño de cada método.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resultados = pd.DataFrame(\n",
    "    {\n",
    "        'Método': [\n",
    "            'KNN crudo (80/20)',\n",
    "            'KNN normalizado Min-Max (80/20)',\n",
    "            'KNN estandarizado Z-score (80/20)',\n",
    "        ],\n",
    "        'Accuracy': [accuracy_raw, accuracy_norm, accuracy_std],\n",
    "    }\n",
    ")\n",
    "\n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cafd7a",
   "metadata": {},
   "source": [
    "---\n",
    "## Preguntas de reflexión y aplicación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bf383",
   "metadata": {},
   "source": [
    "1. ¿Por qué es importante normalizar o estandarizar los datos antes de usar KNN?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ee450",
   "metadata": {},
   "source": [
    "Normalizar o estandarizar garantiza que todas las variables aporten de manera equilibrada al cálculo de distancias. KNN es sensible a la escala: si una característica tiene valores numéricamente grandes (por ejemplo, glucosa) dominará la distancia sobre otras con rangos pequeños (como `Diabetes Pedigree Function`). Al llevar todas las dimensiones a un rango comparable, evitamos sesgos y mejoramos la estabilidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393faba",
   "metadata": {},
   "source": [
    "2. ¿Qué diferencias observaste en el accuracy entre los datos crudos, normalizados y estandarizados?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6273f",
   "metadata": {},
   "source": [
    "El accuracy con datos crudos fue el más bajo, mientras que la normalización Min-Max y la estandarización Z-score mejoraron el desempeño (valores muy similares entre sí). Esto confirma que escalar los atributos ayuda a que la métrica euclidiana sea más representativa en KNN. En este caso la estandarización obtuvo una ligera ventaja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2743a4d",
   "metadata": {},
   "source": [
    "3. Si aumentamos el valor de **k** (número de vecinos), ¿cómo crees que cambiaría el rendimiento del modelo?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817198b3",
   "metadata": {},
   "source": [
    "Al incrementar **k**, cada predicción se basa en un vecindario más amplio, reduciendo la varianza y haciendo el modelo menos sensible al ruido. Sin embargo, si k es demasiado grande puede promediar casos de clases distintas y perder capacidad discriminativa, disminuyendo el accuracy. Suelo elegir k pequeño e impar y luego ajustarlo con validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a02e07",
   "metadata": {},
   "source": [
    "4. ¿Qué ventaja tiene implementar KNN manualmente antes de usar scikit-learn?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b32f9",
   "metadata": {},
   "source": [
    "Implementar KNN manualmente obliga a entender cómo se calculan las distancias, cómo se ordenan los vecinos y cómo se resuelven los empates. Esa intuición facilita interpretar el modelo, depurar posibles errores de preprocesamiento y luego aprovechar scikit-learn con mayor criterio (elegir métrica, k adecuado, ponderación, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc53e18",
   "metadata": {},
   "source": [
    "5. ¿Qué limitaciones presenta KNN cuando se aplica a conjuntos de datos grandes o con muchas dimensiones?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76827e64",
   "metadata": {},
   "source": [
    "KNN requiere almacenar todo el set de entrenamiento y calcular distancias a todos los puntos en cada predicción, por lo que escala mal con muchos registros (costo O(n·d)). Además, en espacios de alta dimensión la distancia euclidiana pierde significado (mal de la dimensionalidad), lo que degrada el rendimiento y exige técnicas de reducción de dimensiones o indexación especializada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707edf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd6c9c",
   "metadata": {},
   "source": [
    "## Rúbrica de evaluación: Práctica KNN\n",
    "\n",
    "| Criterio | Descripción | Puntaje Máximo |\n",
    "|----------|-------------|----------------|\n",
    "| **1. Carga y exploración del dataset** | Carga correcta del archivo CSV, explicación de las variables y verificación de datos. | 15 pts |\n",
    "| **2. Implementación manual de KNN** | Código propio para calcular distancias euclidianas, selección de vecinos y votación mayoritaria. | 20 pts |\n",
    "| **3. Predicción individual (ejemplo aleatorio)** | Explicación clara del proceso paso a paso para un ejemplo de test. | 10 pts |\n",
    "| **4. Uso de scikit-learn (KNN)** | Entrenamiento y evaluación con `train_test_split`, comparación con el método manual. | 15 pts |\n",
    "| **5. Normalización y estandarización** | Aplicación correcta de Min-Max y Z-score, con cálculo de accuracy en cada caso. | 20 pts |\n",
    "| **6. Tabla comparativa de accuracies** | Presentación clara de los resultados y comparación entre métodos. | 10 pts |\n",
    "| **7. Reflexión y preguntas finales** | Respuestas a las preguntas de análisis planteadas (profundidad y claridad). | 10 pts |\n",
    "\n",
    "**Total: 100 pts**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
